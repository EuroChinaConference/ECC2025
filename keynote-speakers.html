<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Keynote Speakers - ECC 2025</title>
    <link rel="stylesheet" href="main.css">
</head>
<body>
    <header>
        <img src="ecc2025.png" alt="ECC 2025 Logo" style="max-width: 200px;">
        <h1>Keynote Speakers</h1>
        <p>ECC 2025 | July 21–23, 2025 | Ostrava, Czech Republic</p>
    </header>
    <nav>
        <ul>
            <li><a href="index.html">Home</a></li>
            <li><a href="call-for-papers.html">Call for Papers</a></li>
            <li><a href="dates.html">Important Dates</a></li>
            <li><a href="submission.html">Paper Submission</a></li>
            <li><a href="sponsors.html">Sponsors</a></li>
            <li><a href="organizing-committee.html">Organizing Committee</a></li>
            <li><a href="keynote-speakers.html">Keynote Speakers</a></li>
            <li><a href="conference-history.html">Conference History</a></li>
            <li><a href="conference-venue.html">Conference Venue</a></li>
              <li><a href="programme.html">Conference Program</a></li>    
        </ul>
    </nav>
    <main>
        <section class="speaker">
            <div class="speaker-container">
                <img src="speaker1.jpg" alt="Speaker 1" class="speaker-photo", style="max-width: 150px;">
                <div class="speaker-details">
                    <h2>Prof. Christian Blum</h2>
                    <h3>Speech Title: On the Use of LLMs in Optimization</h3>
                    <h4>Biography</h4>
                    <p>Dr. Christian Blum is a Senior Research Scientist at the Artificial Intelligence Research Institute (IIIA) of the Spanish National Research Council (CSIC) in Bellaterra, Spain. Previously, from 2012 to 2016, he served as an Ikerbasque Research Professor at the University of the Basque Country in San Sebastian, Spain. He earned a PhD in Applied Sciences from the Free University of Brussels in 2004 and a Diploma (equivalent to a Master’s degree) in Mathematics from the University of Kaiserslautern, Germany, in 1998. His research primarily focuses on swarm intelligence techniques for optimization and control, as well as the hybridization of metaheuristics with other approaches to tackle large-scale optimization problems in fields such as bioinformatics and transportation. Over the past 25 years, Dr. Blum has (co-)authored more than 250 publications in international journals, books, and peer-reviewed conference proceedings. His work has received approximately 21,000 citations, with a current H-index of 46 (Google Scholar). In addition to his research, Dr. Blum serves as an editor for Computers & Operations Research, overseeing heuristics and metaheuristics, and as an associate editor for journals such as the Artificial Intelligence Journal and Engineering Applications of Artificial Intelligence. Throughout his career, he has received various research and supervision awards, including the IEEE Transactions on Evolutionary Computation (IEEE TEC) Outstanding Paper Award and the 2021 SEIO-BBVA award for the best methodological contribution in Operations Research, a prestigious Spanish national award.</p>
                    <h4>Abstract</h4>
                    <p>Large Language Models (LLMs) are AI systems trained on extensive collections of text data, enabling them to understand and generate both natural language and code. Built on transformer architectures—a type of deep learning framework—LLMs process input prompts and produce responses that are supposed to be contextually appropriate. They are highly effective across a broad range of tasks, such as answering questions, summarizing information, writing code, and even making strides in solving mathematical problems. In recent times, the potential of LLMs has been explored in a wide variety of applications. Naturally, researchers in optimization, especially those focused on metaheuristic algorithms, have started investigating how LLMs can be leveraged to enhance their techniques. In this talk, I will present some of our recent work on using LLMs as assistants in optimization research. Examples include the automatic improvement of existing optimization algorithms and the comparative analysis of optimization algorithm performance.</p>
                </div>
            </div>
        </section>
        <section class="speaker">
            <div class="speaker-container">
                <img src="speaker2.jpg" alt="Speaker 2" class="speaker-photo", style="max-width: 150px;">
                <div class="speaker-details">
                    <h2>Prof. Xin Yao</h2>
                    <h3>Speech Title: Online Learning of Data Streams with Concept Drift</h3>
                    <h4>Biography</h4>
                    <p>Prof. Xin Yao is the Vice President (Research and Innovation) and the Tong Tin Sun Chair Professor of Machine Learning at Lingnan University, Hong Kong SAR. He is an IEEE Fellow and was a Distinguished Lecturer of the IEEE Computational Intelligence Society (CIS). He served as the President (2014-15) of IEEE CIS and the Editor-in-Chief (2003-08) of IEEE Transactions on Evolutionary Computation. His major research interests include evolutionary computation, neural network ensembles, and multi-objective learning. His recent interests include online learning, class imbalance learning and trustworthy artificial intelligence. His work won the 2001 IEEE Donald G. Fink Prize Paper Award; 2010, 2016 and 2017 IEEE Transactions on Evolutionary Computation Outstanding Paper Awards; 2011 IEEE Transactions on Neural Networks Outstanding Paper Award; 2010 BT Gordon Radley Award for Best Author of Innovation (Finalist); and many other best paper awards at conferences. He received the 2012 Royal Society Wolfson Research Merit Award, the 2013 IEEE CIS Evolutionary Computation Pioneer Award, and the 2020 IEEE Frank Rosenblatt Award.</p>
                    <h4>Abstract</h4>
                    <p>Data stream mining is a challenging task because the data come only one or a chunk at a time. An online learner has to learn while operating continuously. Such a scenario occurs in numerous real-world scenarios, e.g., condition monitoring,  fault diagnosis, energy consumption, medical tests, financial information, etc. To make the situation more challenging,  the underlying distribution of a data stream may change over time (i.e., a concept drift). This talk first introduces the learning-in-the-model-space framework, which can be used effectively to learn noisy and complex data streams. Online fault diagnosis will be used as an example to illustrate how learning-in-the-model-space could facilitate detecting and classifying unknown faults. Then this talk will present an ensemble approach to tackling concept drifts, i.e., adapting the ensemble diversity after a drift is detected in order to learn new concept quickly and accurately. Finally, this talk will describe a new method for detecting both real and virtual drifts more accurately.</p>
                </div>
            </div>
        </section>
        <section class="speaker">
            <div class="speaker-container">
                <img src="speaker3.jpg" alt="Speaker 3" class="speaker-photo", style="max-width: 150px;">
                <div class="speaker-details">
                    <h2>Prof. Varun Ojha</h2>
                    <h3>Speech Title: Secure Artificial Intelligence on the Edge.</h3>
                    <h4>Biography</h4>
                    <p>Prof. Varun Ojha is a Senior Lecturer (Associate Professor) in Artificial Intelligence at the School of Computing, Newcastle University. He is an Artificial Intelligence Theme Leader and Co-I on the EPSRC-funded National Edge AI Hub. He is AI Lead on  Center of AI Safety at Newcastle University. He works in Artificial Intelligence: Deep Learning, Neural Networks, Machine Learning, and Data Science. In the past, Dr Ojha served as a lecturer (Assistant Professor) in Computer Science at the University of Reading, UK and as a Postdoctoral Fellow at the Swiss Federal Institute of Technology (ETH Zurich), Zurich, Switzerland. Before this, Dr Ojha was a Marie-Curie Fellow (funded by the European Commission) at the Technical University of Ostrava, Czech Republic. More on: ojhavk.github.io.</p>
                    <h4>Abstract</h4>
                    <p>Artificial Intelligence (AI) algorithms have become an inevitable part of our lives and are so pervasive that users often engage with them unconsciously. Both users and systems contribute vast amounts of data to train these algorithms. AI addresses a wide range of critical and sensitive problems, from medical diagnostics and climate change mitigation to assisted driving and financial technologies. However, AI systems have advantages and drawbacks. One significant concern is their security, as they are vulnerable to sophisticated malicious attacks, unintentional changes, omissions of context in training data, sensor aging, changes in the training environment, and other unforeseen circumstances. This makes AI applications at the edge—such as smartphones and cars—susceptible to defects in training data and AI models. Edge AI focuses on safeguarding data integrity and the quality of learning associated with AI algorithms when they are exposed to cyber-attacks in edge computing environments and federated learning. Thus, this talk focuses on the security of AI systems on the edge. </p>
                </div>
            </div>
        </section>

    </main>
    <footer>
        <h3>Contact</h3>
        <ul>
            <li><a href="https://github.com/JZdrazilX">Jan Zdrazil (jan.zdrazil@vsb.cz)</a></li>
            <li><a href="https://github.com/lingping-fuzzy">Lingping Kong (lingping.kong@vsb.cz)</a></li>
        </ul>
    </footer>
</body>
</html>
